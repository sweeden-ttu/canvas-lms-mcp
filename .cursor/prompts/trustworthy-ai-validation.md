---
name: trustworthy-ai-validation
description: Prompt for validating content against Trustworthy AI principles (fairness, privacy, robustness, security, transparency, governance)
---

# Trustworthy AI Validation Prompt

When validating course content, presentations, or generated artifacts, ensure alignment with Trustworthy AI principles:

1. **Fairness** – Content should not reinforce biased representations. Check for inclusive language and balanced treatment of stakeholder perspectives.

2. **Privacy** – No personal data, API tokens, or credentials in content. Verify PII handling is documented.

3. **Robustness** – Error handling, fallbacks, and edge cases are addressed. Validate that failure modes are described.

4. **Security** – Threat model, authentication, and authorization are considered. Check for security-related checklist items.

5. **Transparency** – Explainability of AI/LLM components. Document data sources and model assumptions.

6. **Governance** – Compliance, audit trails, and accountability. Ensure review-changes and reproducibility steps are present.

Use this prompt when running the content validation pipeline or when generating Trustworthy AI presentations. Integrate with LangSmith for evaluation and tracing.
