---
layout: post
title: "Trustworthy AI Legal Validator — Part 4: References and Syllabus Alignment"
date: 2026-01-31
tags: [trustworthy-ai, cs5374, references]
series: trustworthy-legal-validator
part: 4
description: "Research references and syllabus alignment."
---

## Research references (law citations)

1. Stanford Law. Hallucination-Free? Assessing AI Legal Research Tools.  
2. Stanford Law. Large Legal Fictions: Profiling Legal Hallucinations in LLMs.  
3. Mata v. Avianca, Inc., 22-CV-1461 (S.D.N.Y. 2023).  
4. CourtListener API, GARAK, LangChain/LangGraph.

## Syllabus alignment

| Week | Course Topic | Project |
|------|--------------|---------|
| 1–2 | Intro V&V, Adequacy | Problem, verification adequacy |
| 4–6 | Black/white box, Model-based | Output and pipeline validation |
| 8–9 | Graph-based, Fault localization | LangGraph, failure localization |
| 10 | Security testing | Red-team evaluation |
| 16–17 | LangSmith, AI evaluation | Tracing, hallucination metrics |
